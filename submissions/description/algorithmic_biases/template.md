Algorithmic bias occurs in an AI model when the algorithms used to develop the model produce biased outcomes as a result of inherent flaws or limitations in their design. This bias originates from assumptions made during algorithm development, selection of inappropriate models, or the way data is processed and weighted. This results in AI models that make unfair, skewed, or discriminatory decisions.

## Business Impact

Aggregation bias in this AI model can result in reputational damage and indirect financial loss due to the loss of customer trust in the output of the model.

## Steps to Reproduce

1. Select an AI algorithm known to have potential biases
1. Train the algorithm on a dataset that may amplify these biases
1. Test the algorithm's decisions or predictions on a diverse dataset
1. Identify and document instances where the algorithm's output is biased

## Proof of Concept (PoC)

The screenshot(s) below demonstrate(s) the vulnerability:

{{screenshot}}
